{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d657162-ec5d-4672-9222-63e1117734f2",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "This notebook demonstrates the architecture and functionality of a CVE-aware LLM triage agent built for contextual prioritization of security incidents.\n",
    "\n",
    "- Combines semantic search over KEV, NVD, and historical triage records\n",
    "- Uses an MCP tool-exposing agent to make structured, parsable LLM calls\n",
    "- Maintains runtime metrics, batched execution, and persistent historical context\n",
    "\n",
    "Why we do this:\n",
    "Establishes the overall motivation and scope before diving into implementation. Helps readers orient themselves to why each later component exists.\n",
    "Goal: Build a CVE-analysis agent for contextual security triage.\n",
    "Setup: Jupyter notebook, Python 3.10+, Redis via Docker, .env file with OPENAI_API_KEY.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92563e9b-8a03-4b0f-af1b-8c19ca5f309e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dan Guilliams\\OneDrive\\Code Projects\\MCP_Agents_RADSecurity\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "# Why we do this:\n",
    "# Ensures all required Python packages are available in the current environment. This makes the notebook reproducible by others or on fresh systems.\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9fa32f-07fa-4113-a63c-9127ab1eff96",
   "metadata": {},
   "source": [
    "# 2. Start Redis (for idempotency cache)\n",
    "\n",
    "Redis is used by the FastAPI server for request ID deduplication and idempotency protection. Running it locally ensures the pipeline behaves consistently and avoids redundant processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821835c0-5a57-4b51-91e1-180a58d43d9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/local-redis\" is already in use by container \"d7532e8e07eda16696991be756f16a983f49b82035ed57a286f0bc5f0aaafb22\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "\n",
      "Run 'docker run --help' for more information\n"
     ]
    }
   ],
   "source": [
    "# Start Docker Service for Redis:\n",
    "!docker run -d --name local-redis -p 6379:6379 redis:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb242915-b74b-414b-a5d3-016a4c4d5784",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "3. Project Structure\n",
    "\n",
    "Display top-level tree\n",
    "Why we do this:\n",
    "Helps both the developer and the reader understand the overall folder and file layout of the project. This is especially useful for mapping file roles to architectural components.\n",
    "```\n",
    ".\n",
    "├── AI Engineer Take-Home Exercise_ Gen AI Agent for Contextual CVE Analysis.pdf\n",
    "├── Context Summaries\n",
    "├── RADSecurity_Security_Agent-TakeHome.ipynb\n",
    "├── README.md\n",
    "├── README_GEMINI.md\n",
    "├── __init__.py\n",
    "├── __pycache__\n",
    "├── archive\n",
    "├── data\n",
    "│   ├── dummy_agent_incident_analyses.json # Synthetic incident analyses for demo's sake\n",
    "│   ├── dummy_incidents.json # Synthetic historical incidents for demo's sake\n",
    "│   ├── incident_analysis.db # SQLite database\n",
    "│   ├── incidents.json # Actual input data, from RAD Security\n",
    "│   ├── kev.json # Retrieved data via setup/download_cve_data.py\n",
    "│   ├── nvd_subset.json # Isolated data via setup/download_cve_data.py\n",
    "│   ├── nvdcve-1.1-2025.json # Uzipped via setup/download_cve_data.py\n",
    "│   ├── nvdcve-1.1-2025.json.zip # Retrieved data via setup/download_cve_data.py\n",
    "│   └── vectorstore # FAISS indexes\n",
    "│       ├── historical_incidents # Dummy historical incidents + actual incidents (added upon analysis)\n",
    "│       │   ├── index.faiss\n",
    "│       │   └── index.pkl\n",
    "│       ├── kev # Generated KEV data index\n",
    "│       │   ├── index.faiss\n",
    "│       │   └── index.pkl\n",
    "│       └── nvd # NVD data index\n",
    "│           ├── index.faiss\n",
    "│           └── index.pkl\n",
    "├── dev\n",
    "│   ├── incident_dashboard.py # Streamlit app to view SQLite database\n",
    "│   └── query_db.py # Helper to query SQLite database\n",
    "├── examples # Posterity, early experiments with MCP server usage\n",
    "├── experimental # Posterity, early experiments with agents using MCP tools\n",
    "├── logs\n",
    "│   ├── server.log\n",
    "│   └── timing_metrics.log\n",
    "├── main_security_agent_server.py # FastAPI server, hostss the main agent/LLM logic\n",
    "├── mcp_cve_server.py # Hosts the tools used by the agent, called as a subprocess in main_security_agent_server.py\n",
    "├── pyproject.toml\n",
    "├── pytest.ini\n",
    "├── requirements.txt\n",
    "├── run_analysis.py # Main script to run the analysis, calls main_security_agent_server.py asynchronously\n",
    "├── setup\n",
    "│   ├── build_dummy_analyses_index.py # Builds the dummy analyses index\n",
    "│   ├── build_faiss_KEV_and_NVD_indexes.py # Builds the KEV and NVD indexes\n",
    "│   ├── build_historical_incident_analyses_index.py # Builds the historical incidents index\n",
    "│   ├── download_cve_data.py # Downloads the CVE data\n",
    "│   └── README.md # General instructions for initial setup\n",
    "├── tests # Optional, helpful in early discovery and development\n",
    "│   ├── __init__.py\n",
    "│   ├── __pycache__\n",
    "│   ├── test_decorators.py\n",
    "│   └── test_mcp_cve_server.py\n",
    "├── tree_structure.txt # This file for sanity's sake\n",
    "├── utils # Main utility functions that power the project\n",
    "│   ├── __init__.py\n",
    "│   ├── __pycache__\n",
    "│   ├── datastore_utils.py\n",
    "│   ├── decorators.py\n",
    "│   ├── flatteners.py\n",
    "│   ├── logging_utils.py\n",
    "│   ├── prompt_utils.py\n",
    "│   └── retrieval_utils.py\n",
    "└── uv.lock\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69e60c-8ee0-45b1-8554-620229ddf5b0",
   "metadata": {},
   "source": [
    "4. Data Ingestion\n",
    "\n",
    "Load and inspect incidents.json\n",
    "Why we do this:\n",
    "Verifies the most essential input dataset is present, correctly formatted, and structured. This provides a foundation for downstream processing like semantic search and matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ed9439-f5d7-42c4-af97-dd963256293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total incidents: 39\n",
      "Fields in first incident: ['incident_id', 'timestamp', 'title', 'description', 'affected_assets', 'observed_ttps', 'indicators_of_compromise', 'initial_findings']\n",
      "\n",
      "First incident details:\n",
      "{\n",
      "  \"incident_id\": \"INC-2023-08-01-001\",\n",
      "  \"timestamp\": \"2023-08-01T09:15:00Z\",\n",
      "  \"title\": \"Unauthorized Access Attempt on VPN Gateway\",\n",
      "  \"description\": \"Multiple failed login attempts followed by a successful connection from an unusual geographic location on the main VPN gateway.\",\n",
      "  \"affected_assets\": [\n",
      "    {\n",
      "      \"hostname\": \"vpn-gateway-01\",\n",
      "      \"ip_address\": \"203.0.113.1\",\n",
      "      \"os\": \"Cisco IOS XE\",\n",
      "      \"installed_software\": [\n",
      "        {\n",
      "          \"name\": \"Cisco IOS XE\",\n",
      "          \"version\": \"17.3.4a\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"VPN Gateway\"\n",
      "    }\n",
      "  ],\n",
      "  \"observed_ttps\": [\n",
      "    {\n",
      "      \"framework\": \"MITRE ATT&CK\",\n",
      "      \"id\": \"T1110\",\n",
      "      \"name\": \"Brute Force\"\n",
      "    },\n",
      "    {\n",
      "      \"framework\": \"MITRE ATT&CK\",\n",
      "      \"id\": \"T1078\",\n",
      "      \"name\": \"Valid Accounts\"\n",
      "    }\n",
      "  ],\n",
      "  \"indicators_of_compromise\": [\n",
      "    {\n",
      "      \"type\": \"ip_address\",\n",
      "      \"value\": \"172.91.8.123\",\n",
      "      \"context\": \"Source IP of successful login\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"username\",\n",
      "      \"value\": \"admin\",\n",
      "      \"context\": \"Account used for successful login\"\n",
      "    }\n",
      "  ],\n",
      "  \"initial_findings\": \"Credential stuffing or brute force attack successful against VPN.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data')\n",
    "with open(data_dir / 'incidents.json') as f:\n",
    "    incidents = json.load(f)\n",
    "\n",
    "# Display number of incidents and first entry keys\n",
    "print(f\"Total incidents: {len(incidents)}\")\n",
    "print(\"Fields in first incident:\", list(incidents[0].keys()))\n",
    "\n",
    "# Display first incident in pretty format for inspection\n",
    "print(\"\\nFirst incident details:\")\n",
    "print(json.dumps(incidents[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8147ff-8b29-47c9-8cd8-3a611d8be032",
   "metadata": {},
   "source": [
    "Next Steps:\n",
    "- Run `setup/download_cve_data.py` to pull KEV and NVD feeds\n",
    "- Preview kev.json and nvd_subset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87aeecde-d6ae-4ea2-adde-44d90e8ca178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEV entries: 1342\n"
     ]
    }
   ],
   "source": [
    "# Example: load kev.json\n",
    "# Why we do this:\n",
    "# The KEV file contains the CISA Known Exploited Vulnerabilities. Ensuring this loads correctly means the semantic index will have meaningful input to match against.\n",
    "with open(data_dir / 'kev.json') as f:\n",
    "    kev = json.load(f)\n",
    "print(f\"KEV entries: {len(kev.get('vulnerabilities', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e4a6195-1610-4321-b523-b7575e1c6b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVD subset CVEs: 3062\n"
     ]
    }
   ],
   "source": [
    "# Example: load nvd_subset.json\n",
    "# Why we do this:\n",
    "# The NVD subset is a filtered snapshot of a much larger feed. We load it to confirm we have a valid, scoped data source for broader CVE coverage beyond KEV.\n",
    "with open(data_dir / 'nvd_subset.json') as f:\n",
    "    nvd = json.load(f)\n",
    "print(f\"NVD subset CVEs: {len(nvd)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad3f50c-c59a-48e1-aa43-0d4a93570868",
   "metadata": {},
   "source": [
    "## 5. Index Construction & Semantic Retrieval\n",
    "\n",
    "In this section, we build and verify the FAISS indexes for KEV, NVD, and historical data, then demonstrate semantic search.    \n",
    "This shows the robustness of our retrieval layer and ensures the agent has high-signal context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e13a74-4e02-4a2c-acb0-f3fdd9805cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings and FAISS indexes initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Import necessary utilities\n",
    "from utils.flatteners import flatten_kev, flatten_nvd, flatten_incident\n",
    "from utils.retrieval_utils import initialize_embeddings, initialize_indexes, _search\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 5.2 Initialize Embeddings & Indexes\n",
    "# Why we do this:\n",
    "# Embeddings and FAISS indexes underpin retrieval-augmentation. Initializing once at startup ensures fast, consistent access during agent execution.\n",
    "\n",
    "initialize_embeddings()\n",
    "initialize_indexes()\n",
    "print(\"Embeddings and FAISS indexes initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf92ee-fa15-4492-9161-2b96523c4955",
   "metadata": {},
   "source": [
    "### 5.3 Inspect Flattener Outputs\n",
    "\n",
    "Why we do this:    \n",
    "Flatteners convert complex JSON entries into embedding-ready text. Verifying these transformations ensures that our search corpus is well-formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff953c44-ad5e-4794-9126-8d76e27a3cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened KEV document preview:\n",
      "CVE CVE-2025-32756\n",
      "Fortinet\n",
      "Multiple Products\n",
      "Fortinet Multiple Products Stack-Based Buffer Overflow Vulnerability\n",
      "Fortinet FortiFone, FortiVoice, FortiNDR and FortiMail contain a stack-based overflow ...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Flattened NVD document preview:\n",
      "CVE CVE-2025-0020\n",
      "Violation of Secure Design Principles, Hidden Functionality, Incorrect Provision of Specified Functionality vulnerability in ArcGIS (Authentication) allows Privilege Abuse, Manipulat ...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Flattened Incident document preview:\n",
      "Unauthorized Access Attempt on VPN Gateway\n",
      "Multiple failed login attempts followed by a successful connection from an unusual geographic location on the main VPN gateway.\n",
      "Credential stuffing or brute  ...\n"
     ]
    }
   ],
   "source": [
    "# Example KEV entry flattening\n",
    "sample_kev = kev.get('vulnerabilities', [])[0]\n",
    "doc_kev = flatten_kev(sample_kev)\n",
    "print(\"Flattened KEV document preview:\")\n",
    "print(doc_kev.page_content[:200], \"...\")\n",
    "print(f\"\\n{'-'*50}\\n\")\n",
    "\n",
    "# Example NVD entry flattening\n",
    "sample_nvd = list(nvd.values())[0]\n",
    "doc_nvd = flatten_nvd(sample_nvd)\n",
    "print(\"Flattened NVD document preview:\")\n",
    "print(doc_nvd.page_content[:200], \"...\")\n",
    "print(f\"\\n{'-'*50}\\n\")\n",
    "\n",
    "# Example Incident flattening\n",
    "doc_inc = Document(page_content=flatten_incident(incidents[0]), metadata={\"incident_id\": incidents[0][\"incident_id\"]})\n",
    "print(\"Flattened Incident document preview:\")\n",
    "print(doc_inc.page_content[:200], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f46a70-ab52-4ffd-a76d-0f72b5d676ed",
   "metadata": {},
   "source": [
    "### 5.4 Perform a Semantic Search\n",
    "\n",
    "Why we do this:    \n",
    "A simple query over KEV and NVD indexes demonstrates that our retrieval layer returns relevant results. This forms the context the agent uses for decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86a1157-8314-4205-a22e-b3740a1538a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: Unauthorized Access Attempt on VPN Gateway\n",
      "Top 3 KEV matches:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'similarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTop 3 KEV matches:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m kev_results:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mcve_id\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msimilarity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m nvd_results = _search(NVD_FAISS, query_text, k=\u001b[32m3\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTop 3 NVD matches:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'similarity'"
     ]
    }
   ],
   "source": [
    "# We import the FAISS indexes that we initialized earlier, and we can now see a simple result from a sample query\n",
    "from utils.retrieval_utils import KEV_FAISS, NVD_FAISS\n",
    "\n",
    "query_text = incidents[0]['title']\n",
    "print(f\"Search query: {query_text}\")\n",
    "\n",
    "kev_results = _search(KEV_FAISS, query_text, k=3)\n",
    "print(\"Top 3 KEV matches:\")\n",
    "for r in kev_results:\n",
    "    print(f\"- {r['cve_id']} (score: {r['variance']:.3f})\")\n",
    "\n",
    "nvd_results = _search(NVD_FAISS, query_text, k=3)\n",
    "print(\"Top 3 NVD matches:\")\n",
    "for r in nvd_results:\n",
    "    print(f\"- {r['cve_id']} (score: {r['variance']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6d278",
   "metadata": {},
   "source": [
    "# Section 4 – Historical Learning & Retrieval\n",
    "\n",
    "Objective: Demonstrate how the system bootstraps, verifies, and dynamically updates the historical incident analysis FAISS index, enabling context normalization over time.\n",
    "\n",
    "### 4.1 Bootstrapping Historical Index\n",
    "\n",
    "**Goal:** Populate `INCIDENT_HISTORY_FAISS` from existing incidents (e.g., `dummy_incidents.json`).    \n",
    "**Why we do this:** Ensures the agent has an initial set of incident embeddings for similarity search, simulating a production environment with historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see an example of building the historical index via the CLI.  A shell script can simplify the entire setup of downloading initial JSONs, \n",
    "# building the KEV and NVD indexes, and building this index, but it can be worth seeing how the basic logic works.\n",
    "!python setup/build_historical_incident_index.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693e903",
   "metadata": {},
   "source": [
    "### 4.2 Verifying Historical Embeddings\n",
    "\n",
    "**Goal:** Confirm that semantic search over historical analyses returns relevant past incidents.    \n",
    "**Why we do this:** Validates the similarity search and ensures metadata (risk scores, summaries) is correctly embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.retrieval_utils import batch_get_historical_context\n",
    "\n",
    "# Get list of first 5 incident IDs\n",
    "incident_ids = [incident['incident_id'] for incident in incidents[:5]]\n",
    "print(f\"Incident IDs: {incident_ids}\")\n",
    "\n",
    "# Get historical context for these IDs\n",
    "hist_hits = batch_get_historical_context(incident_ids)\n",
    "print(\"\\nHistorical context:\")\n",
    "print(json.dumps(hist_hits, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2e784",
   "metadata": {},
   "source": [
    "### 4.3 Dynamic Addition of New Analyses\n",
    "\n",
    "**Goal:** Show how a newly analyzed incident is added to the historical index on-the-fly.    \n",
    "**Why we do this:** Demonstrates the system's continual learning capability and idempotency safeguards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989579e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from time import sleep\n",
    "from utils.retrieval_utils import add_incident_to_history, INCIDENT_HISTORY_FAISS, search_similar_incidents\n",
    "\n",
    "# We will pick an example incident entry and example analysis (one actually generated by the agent in am previous run)\n",
    "# However, we will change the incident_id for each to ensure it's actually encoded into the index\n",
    "random_incident_id = f\"INC-{random.randint(1000,9999)}-{random.randint(10,99)}-{random.randint(10,99)}-0{random.randint(10,99)}f\"\n",
    "\n",
    "example_incident = {\n",
    "    \"incident_id\": f\"{random_incident_id}\",\n",
    "    \"timestamp\": \"2023-08-13T11:00:00Z\",\n",
    "    \"title\": \"Subdomain Takeover Attempt\",\n",
    "    \"description\": \"Threat intelligence alert indicates a dangling DNS record pointing to a service that is no longer active, potentially allowing subdomain takeover.\",\n",
    "    \"affected_assets\": [\n",
    "      {\n",
    "        \"hostname\": \"old-blog.example.com\",\n",
    "        \"ip_address\": \"N/A\",\n",
    "        \"os\": \"N/A\",\n",
    "        \"installed_software\": [],\n",
    "        \"role\": \"Legacy DNS Entry\"\n",
    "      }\n",
    "    ],\n",
    "    \"observed_ttps\": [\n",
    "      {\n",
    "        \"framework\": \"MITRE ATT&CK\",\n",
    "        \"id\": \"T1584\",\n",
    "        \"name\": \"Compromise Infrastructure\"\n",
    "      },\n",
    "      {\n",
    "        \"framework\": \"MITRE ATT&CK\",\n",
    "        \"id\": \"T1584.001\",\n",
    "        \"name\": \"Compromise Infrastructure: DNS\"\n",
    "      }\n",
    "    ],\n",
    "    \"indicators_of_compromise\": [\n",
    "      {\n",
    "        \"type\": \"dns_record\",\n",
    "        \"value\": \"CNAME old-blog.example.com -> inactive-service.cloudprovider.com\",\n",
    "        \"context\": \"Observed DNS record\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"threat_intel_alert\",\n",
    "        \"value\": \"Dangling DNS record detected\",\n",
    "        \"context\": \"Threat intel alert\"\n",
    "      }\n",
    "    ],\n",
    "    \"initial_findings\": \"Potential subdomain takeover risk due to dangling DNS record.\"\n",
    "  }\n",
    "\n",
    "example_analysis = {\n",
    "    \"incident_id\": f\"{random_incident_id}\",\n",
    "    \"incident_summary\": \"Subdomain Takeover Attempt\",\n",
    "    \"cve_ids\": [\n",
    "      {\n",
    "        \"cve_id\": \"CVE-2023-41265\",\n",
    "        \"cve_summary\": \"HTTP Tunneling Vulnerability in Qlik Sense which could be exploited if a subdomain is compromised.\",\n",
    "        \"cve_relevance\": 1.93,\n",
    "        \"cve_risk_level\": 0.8\n",
    "      }\n",
    "    ],\n",
    "    \"incident_risk_level\": 0.75,\n",
    "    \"incident_risk_level_explanation\": \"Dangling DNS records pose a critical risk for subdomain takeover. The related CVE suggests a known vulnerability in HTTP tunneling that could be leveraged in this context.\"\n",
    "  }\n",
    "\n",
    "print(f\"Adding incident {example_incident['incident_id']} to historical index...\")\n",
    "await add_incident_to_history(example_incident, example_analysis)\n",
    "\n",
    "# We now expect to see entries for this same incident that we just stored to be returned in the search results\n",
    "similar_incidents = search_similar_incidents(example_incident)\n",
    "# The incident_ids will likely differ due to running this script, but we can check a very specific field such as the incident_risk_level_explanation to ensure valid results\n",
    "print(f\"Same incident: {example_analysis['incident_risk_level_explanation'] == similar_incidents[0]['incident_risk_level_explanation']}\")\n",
    "print(f\"{'-'*50}\")\n",
    "# Print the results \n",
    "print(f\"Example Incident:\\n\\tincident_id: {example_incident['incident_id']}\\n\\tincident_summary: {example_analysis['incident_summary']}\\n\\nSimilar incidents: {json.dumps(similar_incidents[:3], indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9483968",
   "metadata": {},
   "source": [
    "### 4.4 Retrieval-Augmented Prompt Enhancement\n",
    "\n",
    "**Goal:** Demonstrate how `batch_get_historical_context` fetches structured past analyses for prompt injection.    \n",
    "**Why we do this:** Shows the exact payload the agent will receive for historical context, ensuring transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.retrieval_utils import batch_get_historical_context\n",
    "\n",
    "batch_ids = [incidents[0]['incident_id'], incidents[1]['incident_id']]\n",
    "historical_context = batch_get_historical_context(batch_ids)\n",
    "\n",
    "print(\"Historical context for batch:\")\n",
    "import json\n",
    "print(json.dumps(historical_context, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0491c1e-ffb6-4532-aba0-b4a30e552908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Next Steps:\n",
    "# - Section 5: Prompt Construction & Agent Execution\n",
    "# - Section 6: Persistence & Dashboard Visualization\n",
    "\n",
    "# %% [markdown]\n",
    "# Section 5 – Prompt Construction & Agent Execution\n",
    "# \n",
    "# Objective: Show how we assemble the complete LLM prompt with context and then invoke the MCP agent to perform the analysis.\n",
    "\n",
    "# %% [markdown]\n",
    "# 5.1 Generate Prompt\n",
    "# \n",
    "# **Goal:** Use `generate_prompt` to combine incident data, KEV/NVD matches, and historical context into a structured System+Human message sequence.\n",
    "# **Why we do this:** Demonstrates how we package all pre-fetched context into a single, token-efficient prompt for the agent.\n",
    "\n",
    "# %%\n",
    "from utils.prompt_utils import generate_prompt, parser\n",
    "from utils.retrieval_utils import batch_match_incident_to_cves, batch_get_historical_context\n",
    "\n",
    "# Prepare batch FAISS and historical results for a sample\n",
    "batch_results = batch_match_incident_to_cves(start_index=0, batch_size=2, top_k=3)\n",
    "historical_results = batch_get_historical_context(incident_ids=[res['incident_id'] for res in batch_results['results']], top_k=2)\n",
    "\n",
    "# Generate the prompt messages\n",
    "prompt_messages = generate_prompt(\n",
    "    query=\"Analyze these incidents and output JSON per Pydantic schema.\",\n",
    "    batch_faiss_results=batch_results,\n",
    "    historical_faiss_results=historical_results\n",
    ")\n",
    "\n",
    "# Preview the system and human messages\n",
    "print(\"System message preview:\")\n",
    "print(prompt_messages[0].content[:500])\n",
    "print(\"Human message preview:\")\n",
    "print(prompt_messages[1].content)\n",
    "\n",
    "# %% [markdown]\n",
    "# 5.2 Instantiate and Run Agent\n",
    "# \n",
    "# **Goal:** Create the ReAct agent with loaded MCP tools and invoke it on our prompt messages.\n",
    "# **Why we do this:** Validates end-to-end integration: tool server, prompt, agent orchestration, and parsing of results.\n",
    "\n",
    "# %%\n",
    "import asyncio\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mcp import ClientSession, stdio_client, StdioServerParameters\n",
    "from utils.logging_utils import setup_logger\n",
    "\n",
    "# Setup server parameters and model\n",
    "server_params = StdioServerParameters(command=\"python\", args=[\"mcp_cve_server.py\"])\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "async def run_agent():\n",
    "    async with stdio_client(server_params) as (r, w):\n",
    "        async with ClientSession(r, w, read_timeout_seconds=15) as session:\n",
    "            await session.initialize()\n",
    "            tools = await load_mcp_tools(session)\n",
    "            agent = create_react_agent(model, tools, name=\"CVE_Agent\")\n",
    "            final_msg, full_response = await agent.ainvoke({\"messages\": prompt_messages})\n",
    "            # Parse using Pydantic\n",
    "            analysis = parser.parse(final_msg.content)\n",
    "            print(\"Analysis result:\")\n",
    "            print(analysis.json(indent=2))\n",
    "\n",
    "# Run the agent (in notebook)\n",
    "await run_agent()\n",
    "\n",
    "# %% [markdown]\n",
    "# 5.3 Inspect Agent Metadata\n",
    "# \n",
    "# **Goal:** Examine token counts and tool-call traces from the agent's full response.\n",
    "# **Why we do this:** Highlights observability and cost metrics captured during execution.\n",
    "\n",
    "# %%\n",
    "# Already captured in `full_response`; we can print key metadata:\n",
    "print(f\"Tokens - input: {full_response['usage_metadata']['input_tokens']}, output: {full_response['usage_metadata']['output_tokens']}, total: {full_response['usage_metadata']['total_tokens']}\")\n",
    "print(\"Tools used:\")\n",
    "for msg in full_response['messages']:\n",
    "    if hasattr(msg, 'additional_kwargs') and msg.additional_kwargs.get('tool_calls'):\n",
    "        for call in msg.additional_kwargs['tool_calls']:\n",
    "            print(f\"- {call['function']['name']}\")\n",
    "\n",
    "# Next: Section 6 – Persistence & Dashboard Visualization\n",
    "# - Section 5: Prompt Construction & Agent Execution\n",
    "# - Section 6: Persistence & Dashboard Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba6615",
   "metadata": {},
   "outputs": [],
   "source": [
    " = {\n",
    "    'incident_id': new_incident['incident_id'],\n",
    "    'incident_risk_level': 0.75,\n",
    "    'incident_risk_level_explanation': 'Simulated risk assessment for demo purposes',\n",
    "    'cve_ids': []\n",
    "}\n",
    "\"\"\"\n",
    "  {\n",
    "    \"incident_id\": \"INC-2023-08-13-038\",\n",
    "    \"incident_summary\": \"Subdomain Takeover Attempt\",\n",
    "    \"cve_ids\": [\n",
    "      {\n",
    "        \"cve_id\": \"CVE-2023-41265\",\n",
    "        \"cve_summary\": \"HTTP Tunneling Vulnerability in Qlik Sense which could be exploited if a subdomain is compromised.\",\n",
    "        \"cve_relevance\": 1.93,\n",
    "        \"cve_risk_level\": 0.8\n",
    "      }\n",
    "    ],\n",
    "    \"incident_risk_level\": 0.75,\n",
    "    \"incident_risk_level_explanation\": \"Dangling DNS records pose a critical risk for subdomain takeover. The related CVE suggests a known vulnerability in HTTP tunneling that could be leveraged in this context.\"\n",
    "  }\n",
    "  \"\"\"\n",
    "print(f\"Adding incident {new_incident['incident_id']} to historical index...\")\n",
    "add_incident_to_history(new_incident, new_analysis)\n",
    "print(\"Addition complete. Verify with another search:\")\n",
    "hits_after = _search(INCIDENT_HISTORY_FAISS, new_incident['title'], k=1)\n",
    "print(f\"Top match after addition: {hits_after[0]['incident_id']} (should be {new_incident['incident_id']})\")\n",
    "\n",
    "# %% [markdown]\n",
    "# 4.4 Retrieval-Augmented Prompt Enhancement\n",
    "# \n",
    "# **Goal:** Demonstrate how `batch_get_historical_context` fetches structured past analyses for prompt injection.\n",
    "# **Why we do this:** Shows the exact payload the agent will receive for historical context, ensuring transparency.\n",
    "\n",
    "# %%\n",
    "from utils.retrieval_utils import batch_get_historical_context\n",
    "\n",
    "batch_ids = [incidents[0]['incident_id'], new_incident['incident_id']]\n",
    "historical_context = batch_get_historical_context(batch_ids)\n",
    "\n",
    "print(\"Historical context for batch:\")\n",
    "import json\n",
    "print(json.dumps(historical_context, indent=2))\n",
    "# %% [markdown]\n",
    "# Next Steps:\n",
    "# - Section 5: Prompt Construction & Agent Execution\n",
    "# - Section 6: Persistence & Dashboard Visualization\n",
    "\n",
    "# %% [markdown]\n",
    "# Section 5 – Prompt Construction & Agent Execution\n",
    "# \n",
    "# Objective: Show how we assemble the complete LLM prompt with context and then invoke the MCP agent to perform the analysis.\n",
    "\n",
    "# %% [markdown]\n",
    "# 5.1 Generate Prompt\n",
    "# \n",
    "# **Goal:** Use `generate_prompt` to combine incident data, KEV/NVD matches, and historical context into a structured System+Human message sequence.\n",
    "# **Why we do this:** Demonstrates how we package all pre-fetched context into a single, token-efficient prompt for the agent.\n",
    "\n",
    "# %%\n",
    "from utils.prompt_utils import generate_prompt, parser\n",
    "from utils.retrieval_utils import batch_match_incident_to_cves, batch_get_historical_context\n",
    "\n",
    "# Prepare batch FAISS and historical results for a sample\n",
    "batch_results = batch_match_incident_to_cves(start_index=0, batch_size=2, top_k=3)\n",
    "historical_results = batch_get_historical_context(incident_ids=[res['incident_id'] for res in batch_results['results']], top_k=2)\n",
    "\n",
    "# Generate the prompt messages\n",
    "prompt_messages = generate_prompt(\n",
    "    query=\"Analyze these incidents and output JSON per Pydantic schema.\",\n",
    "    batch_faiss_results=batch_results,\n",
    "    historical_faiss_results=historical_results\n",
    ")\n",
    "\n",
    "# Preview the system and human messages\n",
    "print(\"System message preview:\")\n",
    "print(prompt_messages[0].content[:500])\n",
    "print(\"Human message preview:\")\n",
    "print(prompt_messages[1].content)\n",
    "\n",
    "# %% [markdown]\n",
    "# 5.2 Instantiate and Run Agent\n",
    "# \n",
    "# **Goal:** Create the ReAct agent with loaded MCP tools and invoke it on our prompt messages.\n",
    "# **Why we do this:** Validates end-to-end integration: tool server, prompt, agent orchestration, and parsing of results.\n",
    "\n",
    "# %%\n",
    "import asyncio\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mcp import ClientSession, stdio_client, StdioServerParameters\n",
    "from utils.logging_utils import setup_logger\n",
    "\n",
    "# Setup server parameters and model\n",
    "server_params = StdioServerParameters(command=\"python\", args=[\"mcp_cve_server.py\"])\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "async def run_agent():\n",
    "    async with stdio_client(server_params) as (r, w):\n",
    "        async with ClientSession(r, w, read_timeout_seconds=15) as session:\n",
    "            await session.initialize()\n",
    "            tools = await load_mcp_tools(session)\n",
    "            agent = create_react_agent(model, tools, name=\"CVE_Agent\")\n",
    "            final_msg, full_response = await agent.ainvoke({\"messages\": prompt_messages})\n",
    "            # Parse using Pydantic\n",
    "            analysis = parser.parse(final_msg.content)\n",
    "            print(\"Analysis result:\")\n",
    "            print(analysis.json(indent=2))\n",
    "\n",
    "# Run the agent (in notebook)\n",
    "await run_agent()\n",
    "\n",
    "# %% [markdown]\n",
    "# 5.3 Inspect Agent Metadata\n",
    "# \n",
    "# **Goal:** Examine token counts and tool-call traces from the agent's full response.\n",
    "# **Why we do this:** Highlights observability and cost metrics captured during execution.\n",
    "\n",
    "# %%\n",
    "# Already captured in `full_response`; we can print key metadata:\n",
    "print(f\"Tokens - input: {full_response['usage_metadata']['input_tokens']}, output: {full_response['usage_metadata']['output_tokens']}, total: {full_response['usage_metadata']['total_tokens']}\")\n",
    "print(\"Tools used:\")\n",
    "for msg in full_response['messages']:\n",
    "    if hasattr(msg, 'additional_kwargs') and msg.additional_kwargs.get('tool_calls'):\n",
    "        for call in msg.additional_kwargs['tool_calls']:\n",
    "            print(f\"- {call['function']['name']}\")\n",
    "\n",
    "# Next: Section 6 – Persistence & Dashboard Visualization\n",
    "# - Section 5: Prompt Construction & Agent Execution\n",
    "# - Section 6: Persistence & Dashboard Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13213e-9131-4e86-870d-fdf9d456bd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4897c9c-a894-40f8-8958-6cad8319b568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
